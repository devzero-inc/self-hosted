# -- Overrides the chart's name.
nameOverride: null

# -- Overrides the chart's computed fullname.
fullnameOverride: null

domain: "domain.example"

credentials:
  registry: ""
  username: ""
  password: ""
  email: ""

image:
  # -- Devzero container image repository'
  repository: docker.io/devzeroinc
  # -- Devzero container image tag'
  tag: "v1.0.0"
  # -- Container pull policy
  pullPolicy: IfNotPresent
  # -- Optionally specify an array of imagePullSecrets
  pullSecrets:
    - pull-secret

workspace:
  image: public.ecr.aws/v1i4e1r2/devzero-devbox-base
  localTag: base-latest

global:
  podAnnotations: {}

serviceAccount:
  # -- Specifies whether a service account should be created
  create: false
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use
  name: "devzero"

gateway:
  # -- Number of replicas for Api Gateway
  replicas: 3

  imageName: "api-gateway"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}


  # Api Gateway autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Api Gateway
    enabled: false
    # -- Minimum autoscaling replicas for Api Gateway
    minReplicas: 1
    # -- Maximum autoscaling replicas for Api Gateway
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Api Gateway
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Api Gateway
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Api Gateway
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Api Gateway
    requests:
      cpu: 100m
      memory: 128Mi

  # Api Gateway service configuration
  service:
    # -- Port of the Api Gateway service
    port: 8443
    # -- Port of the Api Gateway Metrics service
    metricsPort: 9090
    # -- Type of the Api Gateway service
    type: ClusterIP
    # -- Annotations for the Api Gateway service
    annotations: {}
    # -- Labels for the Api Gateway service
    labels: {}

  # Api Gateway ingress configuration
  ingress:
    # -- Specify if the Api Gateway Ingress is enabled
    enabled: enable
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-api-tls
        hosts:
          - "api.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "api.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix


backend:
  # -- Number of replicas for Backend
  replicas: 1

  imageName: "backend"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}

  redis:
    url: redis://dz-control-plane-redis-backend-master:6379
    password: ""

  mongo:
    url: "mongodb://devzero:backend@dz-control-plane-mongodb-0.dz-control-plane-mongodb-headless:27017/backend?directConnection=true"

  hydra:
    apiKey:

  logsrv:
    queue: http://dz-control-plane-elasticmq:9324/queue/logsrv.fifo
    region: "elasticmq"

  github:
    appId: 
    appPrivateKey: ""

  mimir:
    url: http://mimir:8080/prometheus

  hibernation:
    enabled: false

  sendgrid:
    apiKey: test-key

  grafana:
    enabled: true
    datasourceId: "mimir"
    doraDatasourceId: "pulse"
    odaDatasourceId: "timescale"
    password: prom-operator

  storage:
    allowedTeam: team-example-id
    ceph:
      clusterId: ""
      filesystemName: cephfs
      filesystemPath: cephfs
      monitorAddress: /volumes/cache
      userCredentials: ""
      username: vuser

  mainTeamId: ""

  licenseKey: ""
  
  arch: amd64

  cortex:
    key: ""

  # Backend autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Backend
    enabled: false
    # -- Minimum autoscaling replicas for Backend
    minReplicas: 1
    # -- Maximum autoscaling replicas for Backend
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Backend
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Backend
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Backend
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Backend
    requests:
      cpu: 100m
      memory: 128Mi

  # Api Gateway service configuration
  service:
    # -- Port of the Backend service
    port: 8443
    # -- Port of the Backend Metrics service
    metricsPort: 9090
    # -- Type of the Backend service
    type: ClusterIP
    # -- Annotations for the Backend service
    annotations: {}
    # -- Labels for the Backend service
    labels: {}

hydra:
  # -- Number of replicas for Hydra
  replicas: 1

  imageName: "hydra"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}

  job: true

  postgres:
    host: "dz-control-plane-postgres-hydra"
    port: 5432
    name: "postgres"
    user: "hydra"
    password: "hydra"

  redis:
    url: redis://default:@dz-control-plane-redis-hydra-master:6379/0

  cidr:
    v6: fd7a:115c:a1e0::/48
    v4: 100.64.0.0/10

  derp:
    server:
      enabled: false
    urls:
      - "https://controlplane.tailscale.com/derpmap/default"
    paths: []
    autoUpdateEnabled: true
    updateFrequency: "24h"

  # Hydra autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Hydra
    enabled: false
    # -- Minimum autoscaling replicas for Hydra
    minReplicas: 1
    # -- Maximum autoscaling replicas for Hydra
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Hydra
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Hydra
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Hydra
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Hydra
    requests:
      cpu: 100m
      memory: 128Mi

  # Hydra service configuration
  service:
    # -- Port of the Hydra service
    port: 8443
    # -- Port of the Hydra Metrics service
    metricsPort: 9090
    # -- Type of the Hydra service
    type: ClusterIP
    # -- Annotations for the Hydra service
    annotations: {}
    # -- Labels for the Hydra service
    labels: {}

  # Hydra ingress configuration
  ingress:
    # -- Specify if the Hydra Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-hydra-tls
        hosts:
          - "hydra.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "hydra.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix

logsrv:
  # -- Number of replicas for Logsrv
  replicas: 1

  imageName: "logsrv"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}

  queue:
    url: http://dz-control-plane-elasticmq:9324/queue/logsrv.fifo

  postgres:
    url: postgresql://logsrv:logsrv@dz-control-plane-postgres-logsrv:5432/logsrv
    password: logsrv

  refreshJwksTimer: 3600

  # Logsrv autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Logsrv
    enabled: false
    # -- Minimum autoscaling replicas for Logsrv
    minReplicas: 1
    # -- Maximum autoscaling replicas for Logsrv
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Logsrv
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Logsrv
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Logsrv
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Logsrv
    requests:
      cpu: 100m
      memory: 128Mi

  # Logsrv service configuration
  service:
    # -- Port of the Logsrv service
    port: 8443
    # -- Port of the Logsrv Metrics service
    metricsPort: 9090
    # -- Type of the Logsrv service
    type: ClusterIP
    # -- Annotations for the Logsrv service
    annotations: {}
    # -- Labels for the Logsrv service
    labels: {}

  # Logsrv ingress configuration
  ingress:
    # -- Specify if the Logsrv Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-logsrv-tls
        hosts:
          - "logsrv.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "logsrv.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix

polland:
  worker:
    # -- Number of replicas for Polland Worker
    replicas: 3

    # 1 hour of termination grace to allow stacks to finishing tasks
    terminationGracePeriodSeconds: 3600

    # Available queues created from worker
    queues:
      - name: fast
        replicaCount: 1
        autoscaling:
          enabled: false 
          minReplicas: 3
          maxReplicas: 5
      - name: build
        replicaCount: 1
        autoscaling:
          enabled: false 
          minReplicas: 3
          maxReplicas: 5
      - name: workload
        replicaCount: 1
        autoscaling:
          enabled: false 
          minReplicas: 3
          maxReplicas: 5
      - name: cluster
        replicaCount: 1
        autoscaling:
          enabled: false 
          minReplicas: 3
          maxReplicas: 5
      - name: hibernation
        replicaCount: 1
        autoscaling:
          enabled: false
          minReplicas: 1
          maxReplicas: 1

  beat:
    # -- Number of replicas for Polland Beat
    replicas: 1

  flower:
    # -- Number of replicas for Polland Flower
    replicas: 1
    service:
      # -- Port of the Flower service
      port: 5555
      # -- Type of the Flower service
      type: ClusterIP

  celeryExporter:
    # -- Number of replicas for Polland Celery Exporter
    replicas: 1

  # -- Number of replicas for Polland
  replicas: 1

  imageName: "polland"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}

  redis:
    host: dz-control-plane-redis-polland-master
    port: 6379

  # -- Env configuration for polland configmap
  env: 
    MYSQL_PORT: "3306"
    MYSQL_DATABASE: "polland"
    MYSQL_USER: "polland"
    MYSQL_PASSWORD: "polland"
    MYSQL_HOST: "dz-control-plane-mysql-polland-headless"
    MYSQL_ROOT_PASSWORD: "polland"
    REDIS_URL: "redis://dz-control-plane-redis-polland-master:6379/0"

    USE_DOCKER: "yes"
    # Disable connection pooling in preprod because we are running a small container and we don't want to keep connections open.
    CONN_MAX_AGE: "60"
    DJANGO_ALLOWED_HOSTS: "*"
    DJANGO_SETTINGS_MODULE: "config.settings.production"
    # This is supposed to be a secret, but since it is only used to encrypt sessions and we don't use sessions, it can be defined plaintext.
    DJANGO_SECRET_KEY: "super_secret_key"
    CELERY_FLOWER_USER: "devzero"
    CELERY_FLOWER_PASSWORD: "devzero"

    SELF_HOSTED: "True"

    USE_INSECURE_REGISTRY: "True"
    USE_ECR_REGISTRY: "False"
    USE_LOCAL_LOGSRV: "True"

    VAULT_AUTH_METHOD: "kubernetes"
    VAULT_SECRETS_MOUNT_POINT: "vault-csi-production-writer"
    LOGSRV_DEFAULT_QUEUE: "http://dz-control-plane-elasticmq:9324/queue/logsrv.fifo"
    LOGSRV_DEFAULT_REGION: "elasticmq"

  # Polland autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Polland
    enabled: false
    # -- Minimum autoscaling replicas for Polland
    minReplicas: 1
    # -- Maximum autoscaling replicas for Polland
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Polland
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Polland
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Polland
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Polland
    requests:
      cpu: 100m
      memory: 128Mi

  # Polland service configuration
  service:
    # -- Port of the Polland service
    port: 8000
    # -- Port of the Polland Metrics service
    metricsPort: 9090
    # -- Type of the Polland service
    type: ClusterIP
    # -- Annotations for the Polland service
    annotations: {}
    # -- Labels for the Polland service
    labels: {}

pulse:
  # -- Number of replicas for Pulse
  replicas: 1

  imageName: "pulse"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}

  postgres:
    password: pulse
    user: postgres
    host: dz-control-plane
    port: 5432
    database: postgres
    ssl: allow 

  mysql:
    user: pulse
    password: pulse
    host: dz-control-plane-mysql-pulse-headless
    port: 3306
    database: pulse

  devlake:
    secret: ""

  openApi:
    token: ""

  # Pulse autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Pulse
    enabled: false
    # -- Minimum autoscaling replicas for Pulse
    minReplicas: 1
    # -- Maximum autoscaling replicas for Pulse
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Pulse
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Pulse
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Pulse
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Pulse
    requests:
      cpu: 100m
      memory: 128Mi

  # Pulse service configuration
  service:
    # -- Port of the Pulse service
    port: 8443
    # -- Port of the Pulse Metrics service
    metricsPort: 9090
    # -- Type of the Pulse service
    type: ClusterIP
    # -- Annotations for the Pulse service
    annotations: {}
    # -- Labels for the Pulse service
    labels: {}

  ingress:
    # -- Specify if the Pulse Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-pulse-tls
        hosts:
          - "pulse.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "pulse.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix


buildqd:
  # -- Number of replicas for Buildqd
  replicas: 1

  imageName: "buildqd"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  logsrv:
    queue: http://dz-control-plane-elasticmq:9324/queue/logsrv.fifo
    region: elasticmq

  redis:
    url: redis://dz-control-plane-redis-polland-master:6379

  # Buildqd autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Buildqd
    enabled: false
    # -- Minimum autoscaling replicas for Buildqd
    minReplicas: 1
    # -- Maximum autoscaling replicas for Buildqd
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Buildqd
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Buildqd
    targetMemoryUtilizationPercentage: 80

  resources:
    # -- Resource limits for Buildqd
    limits:
      cpu: 1000m
      memory: 1Gi
    # -- Resource requests for Buildqd
    requests:
      cpu: 100m
      memory: 128Mi

  # Buildqd service configuration
  service:
    # -- Port of the Buildqd service
    port: 8443
    # -- Port of the Buildqd Metrics service
    metricsPort: 9090
    # -- Type of the Buildqd service
    type: ClusterIP
    # -- Annotations for the Buildqd service
    annotations: {}
    # -- Labels for the Buildqd service
    labels: {}

  buildkit:
    image:
      # Buildkit repository
      repository: docker.io/moby/buildkit
      # Buildkit image policy
      pullPolicy: IfNotPresent
      # Buildkit image tag
      tag: "v0.15.1"

    # Buildkit container security context
    securityContext:
      privileged: true

    # Buildkit command
    command: buildkitd

    # Buildkit args
    args:
      - --addr
      - unix:///run/buildkit/buildkitd.sock
      - --addr
      - tcp://0.0.0.0:1234
  
    resources:
      # -- Resource limits for Buildqd
      limits:
        cpu: 1000m
        memory: 1Gi
      # -- Resource requests for Buildqd
      requests:
        cpu: 100m
        memory: 128Mi

    # Buildkit persistant volume size for shared cache
    persistentVolumeClaim:
      storageSize: 100Gi

web:
  # -- Number of replicas for Web
  replicas: 1

  imageName: "web"

  # -- Optionally set the scheduler for pods
  schedulerName: ""

  # -- Optionally set the name of the PriorityClass for pods
  priorityClassName: null

  # -- NodeSelector to pin pods to certain set of nodes
  nodeSelector: { }

  # -- Pod affinity settings
  affinity: { }

  # -- Pod tolerations
  tolerations: []

  # -- Pod labels
  podLabels: {}

  # -- Pod annotations
  podAnnotations: {}

  # -- Annotations
  annotations: {}

  # Web autoscaling configuration
  autoscaling:
    # -- Enable autoscaling for Web
    enabled: false
    # -- Minimum autoscaling replicas for Web
    minReplicas: 1
    # -- Maximum autoscaling replicas for Web
    maxReplicas: 3
    # -- Target CPU utilisation percentage for Web
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for Web
    targetMemoryUtilizationPercentage: 80

  # -- Env configuration for web configmap
  env: 
    NEXT_AUTH_ENABLE_CREDENTIALS_PROVIDER: "true"
    NEXT_PUBLIC_BYPASS_AUTH0_FLOW: "true"
    NEXT_PUBLIC_SELF_HOSTED: "true"

  resources:
    # -- Resource limits for Web
    limits:
      cpu: 2000m
      memory: 4Gi
    # -- Resource requests for Web
    requests:
      cpu: 1000m
      memory: 2Gi

  # Web service configuration
  service:
    # -- Port of the Web service
    port: 3000
    # -- Type of the Web service
    type: ClusterIP
    # -- Annotations for the Web service
    annotations: {}
    # -- Labels for the Web service
    labels: {}

  # Web ingress configuration
  ingress:
    # -- Specify if the Web Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-web-tls
        hosts:
          - "{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix

#### External dependencies ####

# Cluster issuer for cert manager
issuer:
  enabled: true

  # ACME server URL
  acme: https://acme-v02.api.letsencrypt.org/directory 
  # Email address used for ACME registration
  email: email@selfzero.net

# Vault external dependencies
vault:
  job: true

  global:
    enabled: true

  injector:
    enabled: false
    metrics:
      enabled: true
  ui:
    enabled: true

  server:
    enabled: true
    ingress:
      enabled: false
    auditStorage:
      enabled: true
    dataStorage:
      enabled: true
    ha:
      enabled: true
      replicas: 3
      config: |
        disable_mlock = true
        ui = true
        
        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
        }
        
        service_registration "kubernetes" {}

        storage "mysql" {
          ha_enabled = true
          address    = "dz-control-plane-mysql-vault-headless"
          username   = "vault"
          password   = "vault"
          database   = "vault"
        }

  ingress:
    # -- Specify if the Vault Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-vault-tls
        hosts:
          - "vault.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "vault.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix

# Postgres external dependencies
postgres-logsrv:
  metrics:
    enabled: true
  
  primary:
    persistence:
      size: "50Gi"
  
  auth:
    database: "logsrv"
    username: "logsrv"
    password: "logsrv"
  
  architecture: "standalone"

postgres-hydra:
  commonAnnotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"

  metrics:
    enabled: true
  
  primary:
    persistence:
      size: "50Gi"
  
  auth:
    database: "postgres"
    username: "hydra"
    password: "hydra"

  architecture: "standalone"

# Mysql external dependencies
mysql-polland:
  commonAnnotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"
  auth:
    username: "polland"
    database: "polland"
    password: "polland"
    rootPassword: "polland"

mysql-pulse:
  commonAnnotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "0"
  auth:
    username: "pulse"
    database: "pulse"
    password: "pulse"
    rootPassword: "pulse"

mysql-vault:
  auth:
    username: "vault"
    database: "vault"
    password: "vault"
    rootPassword: "vault"

# MongoDB external dependencies
mongodb:
  metrics:
    enabled: true
    containerPort: 9090
  
  persistence:
    size: "50Gi"
  
  architecture: "replicaset"
  
  auth:
    usernames:
      - "devzero"
    databases:
      - "backend"
    passwords:
      - "backend"

# Redis external dependencies
redis-backend:
  architecture: "standalone"
  
  master:
    persistence:
      enabled: true
    serviceAccount:
      create: false
  
  serviceAccount:
    create: false
  
  auth:
    enabled: false
  
  replica:
    replicaCount: 0

redis-hydra:
  commonAnnotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-6"

  architecture: "standalone"
  
  master:
    persistence:
      enabled: true
    serviceAccount:
      create: false
  
  serviceAccount:
    create: false
  
  auth:
    enabled: false
  
  replica:
    replicaCount: 0

redis-polland:
  architecture: "standalone"

  commonAnnotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "0"
  
  master:
    persistence:
      enabled: true
    serviceAccount:
      create: false
  
  serviceAccount:
    create: false
  
  auth:
    enabled: false
  
  replica:
    replicaCount: 0

# TimescaleDB external dependencies
timescaledb-single:
  replicaCount: 1
  secrets:
    credentials:
      PATRONI_SUPERUSER_PASSWORD: "pulse"
      PATRONI_REPLICATION_PASSWORD: "pulse"
      PATRONI_admin_PASSWORD: "pulse"

# Elasticmq external dependencies
elasticmq:
  service:
    type: ClusterIP
    port: 9324
  
  elasticmq:
    port: 9324
    config: |
      include classpath("application.conf")
      
      node-address {
          protocol = http
          host = {{ template "elasticmq.fullname" . }}
          port = {{ .Values.elasticmq.port }}
          context-path = ""
      }
      
      rest-sqs {
          enabled = true
          bind-port = {{ .Values.elasticmq.port }}
          bind-hostname = "0.0.0.0"
          // Possible values: relaxed, strict
          sqs-limits = relaxed
      }

      queues {
        "logsrv.fifo" {
          fifo = true
          contentBasedDeduplication = true
        }
      }

# Minio external dependencies
minio:
  replicas: 5

  resources:
    requests:
      memory: 2Gi

# Docker registry external dependencies
registry:
  ingress:
    # -- Specify if the Docker registry Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/proxy-body-size: "200g"
    # -- TLS
    tls:
      - secretName: devzero-registry-tls
        hosts:
          - "registry.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "registry.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix

grafana:
  ingress:
    # -- Specify if the Grafana Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-grafana-tls
        hosts:
          - "grafana.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "grafana.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix

mimir:
  ingress:
    # -- Specify if the Mimir Ingress is enabled
    enabled: true
    # -- Ingress Class Name. May be required for k8s >= 1.18
    ingressClassName: "nginx"
    # -- Annotations
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-self-hosted"
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # -- TLS
    tls:
      - secretName: devzero-mimir-tls
        hosts:
          - "mimir.{{ .Values.domain }}"
    # -- Hosts
    hosts:
      - host: "mimir.{{ .Values.domain }}"
        paths:
          - path: /
            pathType: Prefix


kube-prometheus-stack:
  grafana:
    grafana.ini:
      auth.jwt:
        enabled: true
        username_claim: "sub"
        enable_login_token: true
        header_name: "X-JWT-Assertion"
        auto_sign_up: true
        url_login: true
        jwk_set_url: "https://devinfra.us.auth0.com/.well-known/jwks.json"
        skip_org_role_sync: true
      auth.anonymous:
        enabled: true
        org_name: "Main Org."
        org_role: "Viewer"
      security:
        allow_embedding: true
        cookie_samesite: "disabled"
      public_dashboards:
        enabled: true
    defaultDashboardsEnabled: false
    persistence:
      enabled: true
      type: "sts"
      accessModes:
        - "ReadWriteOnce"
      size: "10Gi"
      finalizers:
        - "kubernetes.io/pvc-protection"
    additionalDataSources:
      - name: mimir
        access: proxy
        orgId: 1
        version: 1
        type: prometheus
        uid: "mimir"
        url: https://{{ printf "%s-mimir-nginx.svc" .Release.Name }}:80
      - name: pulse
        access: proxy
        orgId: 1
        version: 1
        uid: "pulse"
        type: mysql
        url: https://{{ printf "%s-mysql-pulse.svc" .Release.Name }}:3306
        user: "pulse"
        secureJsonData:
          password: "pulse"
        jsonData:
          database: "pulse"
      - name: timescale
        access: proxy
        orgId: 1
        version: 1
        uid: "timescale"
        type: "postgres"
        url: https://{{ printf "%s-0.svc" .Release.Name }}:5432
        user: "tsdbadmin"
        secureJsonData:
          password: "pulse"
        jsonData:
          database: "tsdb"

mimir-distributed:
  mimir:
    structuredConfig:
      limits:
        max_global_series_per_user: 10000000
        request_rate: 0
        request_burst_size: 0
        ingestion_rate: 1000000
        ingestion_burst_size: 100000000

      querier:
        max_concurrent: 512

      query_scheduler:
        max_outstanding_requests_per_tenant: 4096

  ingester:
    persistentVolume:
      size: "100Gi"

  compactor:
    persistentVolume:
      size: "100Gi"

  store_gateway:
    persistentVolume:
      size: "100Gi"

  alertmanager:
    enabled: false

  ruler:
    enabled: false

  overrides_exporter:
    enabled: false

  query_scheduler:
    enabled: false

  minio:
    enabled: true
